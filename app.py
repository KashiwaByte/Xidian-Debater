
import gradio as gr
import openai, subprocess
from pathlib import Path
import os
import azure.cognitiveservices.speech as speechsdk
import uuid

# Azure tts è®¾å®š
SPEECH_REGION='eastus'
SPEECH_KEY= 'af2d4aa2348b4b73b60487c73e0eb431'

speech_config = speechsdk.SpeechConfig(subscription='af2d4aa2348b4b73b60487c73e0eb431', region='eastus')
audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)

# The language of the voice that speaks.
speech_config.speech_synthesis_voice_name='	zh-CN-XiaoxiaoNeural'

speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)



# åˆå§‹å˜é‡è®¾å®š
openai.api_key = None
debatetype = 'ä½ æ˜¯ä¸€åé€»è¾‘æ€§å¾ˆå¼ºçš„èµ„æ·±è¾©æ‰‹ï¼Œä½ æ“…é•¿é€šè¿‡æ•°æ®è®ºæ®å’Œå­¦ç†è®ºæ®æ¥åé©³ï¼Œä½ çš„åé©³æ€»æ˜¯ä¸€é˜µè§è¡€ï¼Œè€Œä¸”å¾ˆæœ‰é€»è¾‘æ€§ã€‚æ¥ä¸‹æ¥æˆ‘ä¼šæå‡ºæˆ‘çš„è§‚ç‚¹ï¼Œä½ éœ€è¦åšçš„å°±æ˜¯é’ˆé”‹ç›¸å¯¹åœ°åé©³æˆ‘'
username=' '
messages = [{"role": "system", "content": debatetype}]
chat_transcript = ""
sessions={}
uuid_count=0


# sttå’Œttså‡½æ•°
def transcribe(audio,session_id):
    global messages
    global chat_transcript 
    global speech_synthesizer
    global sessions
    global api_key
    global debate_prompt
    global username
    # è·å–å½“å‰ä¼šè¯çš„ä¿¡æ¯
    session = sessions[session_id]
    api_key = session["api_key"]
    debate_prompt = session["debate_prompt"]
    username = session["username"]
    messages = session["messages"]

    #å¯¹è¯å¤„ç†
    myfile=Path(audio)
    myfile=myfile.rename(myfile.with_suffix('.wav'))
    audio_file = open(myfile,"rb")
    transcript = openai.Audio.transcribe("whisper-1", audio_file)

    messages.append({"role": "user", "content": transcript["text"]})

    response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages)

    system_message = response["choices"][0]["message"]

    messages.append(system_message)

    #æ›´æ–°ä¼šè¯ä¸Šä¸‹æ–‡
    session["messages"] = messages
    sessions[session_id] = session

    speech_synthesis_result = speech_synthesizer.speak_text_async(system_message['content']).get()
    stream = stream = speechsdk.AudioDataStream(speech_synthesis_result)
    stream.save_to_wav_file("outputs.wav")
    # åŸwindows tts è§£å†³æ–¹æ¡ˆ  subprocess.call(["wsay", system_message['content']])

    chat_transcript = ""
    for message in messages:
        if message['role'] != 'system':
            chat_transcript += message['role'] + ": " + message['content'] + "\n\n"

    return chat_transcript,'outputs.wav'

# è®°å½•æ¶ˆé™¤å‡½æ•°
def eraser(session_id):
    global sessions
    global messages
    session = sessions[session_id]
    messages = session["messages"]
    messages = [{"role": "system", "content": debatetype}]
     #æ›´æ–°ä¼šè¯ä¸Šä¸‹æ–‡
    session["messages"] = messages
    sessions[session_id] = session
    print('æ“¦é™¤æˆåŠŸâœï¸ğŸ§½')

# åˆå§‹åŒ–å‡½æ•°
def initway(api_key,debateprompt,name):
    global sessions
    global uuid_count
    openai.api_key =api_key
    debatetype=debateprompt
    username=name 
    messages = [{"role": "system", "content": debatetype}]

    uuid_count+=1
    session_id=str(uuid.uuid4())     # ç”ŸæˆUUID
    sessions[session_id]={
        "api_key": api_key,
        "debate_prompt": debateprompt,
        "username": username,
        "messages": [{"role": "system", "content": debatetype}]
    }
    print("åˆå§‹åŒ–æˆåŠŸï¼ğŸ‰")
    print("å½“å‰ä½¿ç”¨è€…ï¼š"+ username)
    print("å½“å‰uuid:"+ session_id)
    print("å½“å‰è¾©é£:" + debatetype)
    print('å½“å‰å·²æœåŠ¡:'+str(uuid_count)+'(äººæ¬¡)')
    return session_id

title = "<h1 style='font-size: 40px;'><center>Xidian-Debater</center></h1>"
author="<p align='center' style='font-size: 20px;'> äººå·¥æ™ºèƒ½å­¦é™¢è¾©è®ºé˜ŸKashiwaå‡ºå“</p>"
css1 = """
.h1 {
  text-align: center ;
}
   """

with gr.Blocks(css="#chatbot{height:300px} .overflow-y-auto{height:500px}") as init:
    gr.Markdown(title)
    gr.Markdown(author)
    with gr.Row():
        api_key = gr.Textbox(
            lines=2, placeholder="api_key Here...", label="api_key",value="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")
        debateprompt = gr.Textbox(
            lines=5, placeholder="style Here...", label="è¾©é£" ,value="ä½ æ˜¯ä¸€åé€»è¾‘æ€§å¾ˆå¼ºçš„èµ„æ·±è¾©æ‰‹ï¼Œä½ æ“…é•¿é€šè¿‡æ•°æ®è®ºæ®å’Œå­¦ç†è®ºæ®æ¥åé©³ï¼Œä½ çš„åé©³æ€»æ˜¯ä¸€é˜µè§è¡€ï¼Œè€Œä¸”å¾ˆæœ‰é€»è¾‘æ€§ã€‚æ¥ä¸‹æ¥æˆ‘ä¼šæå‡ºæˆ‘çš„è§‚ç‚¹ï¼Œä½ éœ€è¦åšçš„å°±æ˜¯é’ˆé”‹ç›¸å¯¹åœ°åé©³æˆ‘ï¼Œæ¯æ¬¡å›ç­”ä¸è¶…è¿‡100ä¸ªå­—")
       
    with gr.Row():
        session_id_get=gr.Textbox(label="å½“å‰uuid")
        name = gr.Textbox(label="å½“å‰ä½¿ç”¨è€…å§“å")
    btn = gr.Button(value="åˆå§‹åŒ–")
    btn.click(initway, [api_key, debateprompt,name],[session_id_get])


Debate= gr.Blocks(css=css1)
with Debate:
    gr.Markdown(title)
    gr.Markdown(author)
    session_idin=gr.Textbox(label="è¯·è¾“å…¥uuid")
    with gr.Row():
        trans = gr.Button("ğŸ­ è½¬å½•")
        output_button = gr.Button("é‡ç½®ğŸ§½")
    with gr.Row():
        audio_in=gr.Audio(source="microphone", type="filepath",label="è¯­éŸ³è¾“å…¥")
        audio_out=gr.Audio(source="microphone", type="filepath",label="è¯­éŸ³è¾“å‡º")
    
    output_transcript = gr.Textbox(label="å¯¹è¯åŒº")
    trans.click(transcribe, [audio_in,session_idin],[output_transcript,audio_out])
    output_button.click(eraser,[session_idin])
   
# test=gr.Interface(fn=transcribe, inputs=gr.Audio(source="microphone", type="filepath"), outputs="text")

ui = gr.TabbedInterface([init,Debate],["åˆå§‹åŒ–","è¾©è®º",])
ui.launch(share=True)