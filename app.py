
import gradio as gr
import openai, subprocess
from pathlib import Path
import os
import azure.cognitiveservices.speech as speechsdk


# Azure tts
# This example requires environment variables named "SPEECH_KEY" and "SPEECH_REGION"
SPEECH_REGION='eastus'
SPEECH_KEY= 'af2d4aa2348b4b73b60487c73e0eb431'

speech_config = speechsdk.SpeechConfig(subscription='af2d4aa2348b4b73b60487c73e0eb431', region='eastus')
audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)

# The language of the voice that speaks.
speech_config.speech_synthesis_voice_name='	zh-CN-XiaoxiaoNeural'

speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)


# æ¢æˆä½ è‡ªå·±çš„api_key
openai.api_key = "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"
debatestyle = " "
messages = [{"role": "system", "content": 'ä½ æ˜¯ä¸€åé€»è¾‘æ€§å¾ˆå¼ºçš„èµ„æ·±è¾©æ‰‹ï¼Œä½ æ“…é•¿é€šè¿‡æ•°æ®è®ºæ®å’Œå­¦ç†è®ºæ®æ¥åé©³ï¼Œä½ çš„åé©³æ€»æ˜¯ä¸€é˜µè§è¡€ï¼Œè€Œä¸”å¾ˆæœ‰é€»è¾‘æ€§ã€‚æ¥ä¸‹æ¥æˆ‘ä¼šæå‡ºæˆ‘çš„è§‚ç‚¹ï¼Œä½ éœ€è¦åšçš„å°±æ˜¯é’ˆé”‹ç›¸å¯¹åœ°åé©³æˆ‘'}]
chat_transcript = ""
def transcribe(audio):
    global messages
    global chat_transcript
    global speech_synthesizer
    myfile=Path(audio)
    myfile=myfile.rename(myfile.with_suffix('.wav'))
    audio_file = open(myfile,"rb")
    transcript = openai.Audio.transcribe("whisper-1", audio_file)

    messages.append({"role": "user", "content": transcript["text"]})

    response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages)

    system_message = response["choices"][0]["message"]
    # print(response)
    messages.append(system_message)

    speech_synthesis_result = speech_synthesizer.speak_text_async(system_message['content']).get()
    
    # åŸwindows tts è§£å†³æ–¹æ¡ˆ  subprocess.call(["wsay", system_message['content']])

    chat_transcript = ""
    for message in messages:
        if message['role'] != 'system':
            chat_transcript += message['role'] + ": " + message['content'] + "\n\n"

    return chat_transcript

def eraser():
    global messages
    messages = [{"role": "system", "content": 'ä½ æ˜¯ä¸€åé€»è¾‘æ€§å¾ˆå¼ºçš„èµ„æ·±è¾©æ‰‹ï¼Œä½ æ“…é•¿é€šè¿‡æ•°æ®è®ºæ®å’Œå­¦ç†è®ºæ®æ¥åé©³ï¼Œä½ çš„åé©³æ€»æ˜¯ä¸€é˜µè§è¡€ï¼Œè€Œä¸”å¾ˆæœ‰é€»è¾‘æ€§ã€‚æ¥ä¸‹æ¥æˆ‘ä¼šæå‡ºæˆ‘çš„è§‚ç‚¹ï¼Œä½ éœ€è¦åšçš„å°±æ˜¯é’ˆé”‹ç›¸å¯¹åœ°åé©³æˆ‘ï¼Œæ¯æ¬¡å›ç­”ä¸è¶…è¿‡100ä¸ªå­—'}]
    print('æ“¦é™¤æˆåŠŸâœï¸ğŸ§½')

def initway(api_key,style):
    openai.api_key =api_key

    debatestyle = style
    print("åˆå§‹åŒ–æˆåŠŸï¼ğŸ‰")



with gr.Blocks(css="#chatbot{height:300px} .overflow-y-auto{height:500px}") as init:
    with gr.Row():
        api_key = gr.Textbox(
            lines=1, placeholder="api_key Here...", label="api_key",value="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")
        style = gr.Textbox(
            lines=1, placeholder="style Here...", label="è¾©é£" ,value="ä½ æ˜¯ä¸€åé€»è¾‘æ€§å¾ˆå¼ºçš„èµ„æ·±è¾©æ‰‹ï¼Œä½ æ“…é•¿é€šè¿‡æ•°æ®è®ºæ®å’Œå­¦ç†è®ºæ®æ¥åé©³ï¼Œä½ çš„åé©³æ€»æ˜¯ä¸€é˜µè§è¡€ï¼Œè€Œä¸”å¾ˆæœ‰é€»è¾‘æ€§ã€‚æ¥ä¸‹æ¥æˆ‘ä¼šæå‡ºæˆ‘çš„è§‚ç‚¹ï¼Œä½ éœ€è¦åšçš„å°±æ˜¯é’ˆé”‹ç›¸å¯¹åœ°åé©³æˆ‘ï¼Œæ¯æ¬¡å›ç­”ä¸è¶…è¿‡100ä¸ªå­—")
        btn = gr.Button(value="åˆå§‹åŒ–")
        btn.click(initway, [api_key, style])

with gr.Blocks(css="#chatbot{height:300px} .overflow-y-auto{height:500px}") as Debate:
    with gr.Row():
        audio=gr.Audio(source="microphone", type="filepath",label="è¯­éŸ³è¾“å…¥")
        trans = gr.Button("ğŸ­ è½¬å½•")
        output_button = gr.Button("é‡ç½®ğŸ§½")
    with gr.Row():
        output_transcript = gr.Textbox(label="è¯­éŸ³è½¬å½•è¾“å‡º")
    trans.click(transcribe, [audio],[output_transcript])
    output_button.click(eraser)
   
test=gr.Interface(fn=transcribe, inputs=gr.Audio(source="microphone", type="filepath"), outputs="text")

ui = gr.TabbedInterface([init,Debate,test],["åˆå§‹åŒ–","è¾©è®º","æµ‹è¯•"])
ui.launch()