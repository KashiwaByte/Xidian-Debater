
import gradio as gr
import openai, subprocess
from pathlib import Path
import os
import azure.cognitiveservices.speech as speechsdk


# Azure tts
# This example requires environment variables named "SPEECH_KEY" and "SPEECH_REGION"
SPEECH_REGION='eastus'
SPEECH_KEY= 'af2d4aa2348b4b73b60487c73e0eb431'

speech_config = speechsdk.SpeechConfig(subscription='af2d4aa2348b4b73b60487c73e0eb431', region='eastus')
audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)

# The language of the voice that speaks.
speech_config.speech_synthesis_voice_name='	zh-CN-XiaoxiaoNeural'

speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)



# æ¢æˆä½ è‡ªå·±çš„api_key
openai.api_key = None
debatetype = 'ä½ æ˜¯ä¸€åé€»è¾‘æ€§å¾ˆå¼ºçš„èµ„æ·±è¾©æ‰‹ï¼Œä½ æ“…é•¿é€šè¿‡æ•°æ®è®ºæ®å’Œå­¦ç†è®ºæ®æ¥åé©³ï¼Œä½ çš„åé©³æ€»æ˜¯ä¸€é˜µè§è¡€ï¼Œè€Œä¸”å¾ˆæœ‰é€»è¾‘æ€§ã€‚æ¥ä¸‹æ¥æˆ‘ä¼šæå‡ºæˆ‘çš„è§‚ç‚¹ï¼Œä½ éœ€è¦åšçš„å°±æ˜¯é’ˆé”‹ç›¸å¯¹åœ°åé©³æˆ‘'
username=' '
messages = [{"role": "system", "content": debatetype}]
chat_transcript = ""
def transcribe(audio):
    global messages
    global chat_transcript 
    global speech_synthesizer
    myfile=Path(audio)
    myfile=myfile.rename(myfile.with_suffix('.wav'))
    audio_file = open(myfile,"rb")
    transcript = openai.Audio.transcribe("whisper-1", audio_file)

    messages.append({"role": "user", "content": transcript["text"]})

    response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages)

    system_message = response["choices"][0]["message"]
    # print(response)
    messages.append(system_message)

    speech_synthesis_result = speech_synthesizer.speak_text_async(system_message['content']).get()
    
    # åŸwindows tts è§£å†³æ–¹æ¡ˆ  subprocess.call(["wsay", system_message['content']])

    chat_transcript = ""
    for message in messages:
        if message['role'] != 'system':
            chat_transcript += message['role'] + ": " + message['content'] + "\n\n"

    return chat_transcript

def eraser():
    global messages
    messages = [{"role": "system", "content": debatetype}]
    print('æ“¦é™¤æˆåŠŸâœï¸ğŸ§½')

def initway(api_key,debateprompt,name):
    openai.api_key =api_key
    debatetype=debateprompt
    username=name 
    messages = [{"role": "system", "content": debatetype}]
    print("åˆå§‹åŒ–æˆåŠŸï¼ğŸ‰")
    print("å½“å‰ä½¿ç”¨è€…ï¼š"+ username)
    print("å½“å‰è¾©é£:" + debatetype)
    print(messages)

title = "<h1 style='font-size: 40px;'><center>Xidian-Debater</center></h1>"
author="<p align='center' style='font-size: 20px;'> äººå·¥æ™ºèƒ½å­¦é™¢Kashiwaå‡ºå“</p>"
css1 = """
.h1 {
  text-align: center ;
}
   """

with gr.Blocks(css="#chatbot{height:300px} .overflow-y-auto{height:500px}") as init:
    gr.Markdown(title)
    gr.Markdown(author)
    with gr.Row():
        api_key = gr.Textbox(
            lines=2, placeholder="api_key Here...", label="api_key",value="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")
        debateprompt = gr.Textbox(
            lines=5, placeholder="style Here...", label="è¾©é£" ,value="ä½ æ˜¯ä¸€åé€»è¾‘æ€§å¾ˆå¼ºçš„èµ„æ·±è¾©æ‰‹ï¼Œä½ æ“…é•¿é€šè¿‡æ•°æ®è®ºæ®å’Œå­¦ç†è®ºæ®æ¥åé©³ï¼Œä½ çš„åé©³æ€»æ˜¯ä¸€é˜µè§è¡€ï¼Œè€Œä¸”å¾ˆæœ‰é€»è¾‘æ€§ã€‚æ¥ä¸‹æ¥æˆ‘ä¼šæå‡ºæˆ‘çš„è§‚ç‚¹ï¼Œä½ éœ€è¦åšçš„å°±æ˜¯é’ˆé”‹ç›¸å¯¹åœ°åé©³æˆ‘ï¼Œæ¯æ¬¡å›ç­”ä¸è¶…è¿‡100ä¸ªå­—")
       
    with gr.Row():
         drop1 = gr.Radio(["æ­£åœ¨ä½¿ç”¨", "æ— äººä½¿ç”¨", ],
                     label="çŠ¶æ€é€‰æ‹©", info="å¯åœ¨æ— äººä½¿ç”¨æ—¶ä½¿ç”¨ï¼Œä½¿ç”¨æ—¶è¯·ç‚¹å‡»æŒ‰é’®å¹¶è¾“å…¥ç”¨æˆ·åï¼Œä½¿ç”¨ç»“æŸè®°å¾—ç‚¹å‡»é‡ç½®")  # å•é€‰
         name = gr.Textbox(label="å½“å‰ä½¿ç”¨è€…å§“å")
    btn = gr.Button(value="åˆå§‹åŒ–")
    btn.click(initway, [api_key, debateprompt,name])


Debate= gr.Blocks(css=css1)
with Debate:
    gr.Markdown(title)
    gr.Markdown(author)
    with gr.Row():
        audio=gr.Audio(source="microphone", type="filepath",label="è¯­éŸ³è¾“å…¥")
        trans = gr.Button("ğŸ­ è½¬å½•")
        output_button = gr.Button("é‡ç½®ğŸ§½")
    with gr.Row():
        output_transcript = gr.Textbox(label="è¯­éŸ³è½¬å½•è¾“å‡º")
    trans.click(transcribe, [audio],[output_transcript])
    output_button.click(eraser)
   
# test=gr.Interface(fn=transcribe, inputs=gr.Audio(source="microphone", type="filepath"), outputs="text")

ui = gr.TabbedInterface([init,Debate],["åˆå§‹åŒ–","è¾©è®º",])
ui.launch(share=True)